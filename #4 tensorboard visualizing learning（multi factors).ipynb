{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#encoding:UTF-8\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('MNIST-data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.查看数据基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"训练数据共：\"+str(len(data.train.images))\n",
    "print \"测试数据共：\"+str(len(data.test.images))\n",
    "print \"第一个测试图的维度：\"+str(data.test.images[0].shape)\n",
    "print \"第一个测试图的真实值：\"+str(data.test.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.检测数据与标签是否对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape((28,28)), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"label: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = data.test.images[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = np.argmax(data.test.labels[0:9],1)\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.显示所有操作节点\n",
    "### 2.显示name_scope，集合\n",
    "### 3.显示图片\n",
    "### 4.显示损失函数和准确率\n",
    "### 5.显示直方图📊（权重、偏差等）\n",
    "### 6.不同学习率等参数的学习率变化\n",
    "### 7.embedding将数据投射到3D图中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define convolutional layer function\n",
    "def conv_fun(name,input,input_channels,output_channels):\n",
    "    # collect all nodes bellow\n",
    "    with tf.name_scope(name):\n",
    "        # w for weights\n",
    "        w = tf.Variable(tf.truncated_normal(stddev=0.5,shape=[5,5,input_channels,output_channels]),name=\"conv_w\")\n",
    "        # b for biases\n",
    "        b = tf.Variable(tf.constant(0.5,shape=[output_channels]),name=\"conv_b\")\n",
    "        # summary histogram of w & b\n",
    "        tf.summary.histogram(\"conv_w\",w)\n",
    "        tf.summary.histogram(\"conv_b\",b)\n",
    "        # convolute \n",
    "        conv_layer = tf.nn.conv2d(\n",
    "            input = input,\n",
    "            filter = w,\n",
    "            strides = [1,1,1,1],\n",
    "            padding=\"SAME\",\n",
    "            name=\"conv_op\"\n",
    "        )\n",
    "\n",
    "        # add biases\n",
    "        conv_layer = tf.add(conv_layer,b,name=\"conv_add\")\n",
    "        # relu\n",
    "        conv_layer = tf.nn.relu(conv_layer,name=\"conv_relu\")\n",
    "    \n",
    "        return conv_layer\n",
    "\n",
    "# define pooling layer function\n",
    "def pool_fun(name,input):\n",
    "    # collect all nodes bellow\n",
    "    with tf.name_scope(name):\n",
    "        # max pool\n",
    "        pool_layer = tf.nn.max_pool(\n",
    "            value = input,\n",
    "            ksize = [1,2,2,1],\n",
    "            strides = [1,2,2,1],\n",
    "            padding=\"SAME\",\n",
    "            name = \"pool_op\"\n",
    "        )\n",
    "        return pool_layer\n",
    "\n",
    "\n",
    "#define fully connected layer function     \n",
    "def fl_fun(name,input,input_channels,output_channels):\n",
    "    # collect all nodes bellow    \n",
    "    with tf.name_scope(name):\n",
    "        # weights & biases\n",
    "        w = tf.Variable(tf.truncated_normal(stddev=0.5,shape=[input_channels,output_channels]),name=\"fl_w\")\n",
    "        b = tf.Variable(tf.constant(0.5,shape=[output_channels]),name=\"fl_b\")\n",
    "        # summary histogram of w & b\n",
    "        tf.summary.histogram(\"fl_w\",w)\n",
    "        tf.summary.histogram(\"fl_b\",b)\n",
    "        # add biases\n",
    "        fl = tf.add(tf.matmul(input,w),b,name = \"fl_add\")\n",
    "        \n",
    "        return fl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate different string\n",
    "def generate(learning_rate,use_two_conv,use_two_fl):\n",
    "    str_a = 2 if use_two_conv else 1\n",
    "    str_b = 2 if use_two_fl else 1\n",
    "    return \"lr_%s,conv=%s,fl=%s\" % (learning_rate,str_a,str_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main model to evaluate different conditions \n",
    "def minst_model(lr,use_two_conv,use_two_fl):\n",
    "    # must reset\n",
    "    tf.reset_default_graph()\n",
    "    # x for input \n",
    "    x = tf.placeholder(tf.float32,[None,784],name=\"x\")\n",
    "    # reshape x to NHWC format matrix\n",
    "    x_reshape = tf.reshape(x,[-1,28,28,1],name=\"x_reshape\")\n",
    "    # summary input images\n",
    "    tf.summary.image(\"input_images\",x_reshape)\n",
    "    \n",
    "    # use two convolutional layers\n",
    "    if use_two_conv:\n",
    "        # conv1,shape :[-1,28,28,32]\n",
    "        conv1 = conv_fun(\"conv1\",x_reshape,1,32)    \n",
    "        # pool1 ,shape: [-,14,14,32]\n",
    "        pool1 = pool_fun(\"pool1\",conv1)\n",
    "        # conv2 ,shape:[-1,14,14,64]\n",
    "        conv2 = conv_fun(\"conv2\",pool1,32,64)\n",
    "        # pool2, shape:[-1,7,7,64]\n",
    "        pool2 = pool_fun(\"pool2\",conv2)\n",
    "    # only use one conv layer\n",
    "    else:\n",
    "        # conv1,shape :[-1,28,28,64]\n",
    "        conv1 = conv_fun(\"conv1\",x_reshape,1,64)    \n",
    "        # pool1 ,shape: [-,14,14,64]\n",
    "        pool1 = pool_fun(\"pool1\",conv1)\n",
    "        # pool2, shape:[-1,7,7,64]        \n",
    "        pool2 = pool_fun(\"pool2\",pool1)\n",
    "\n",
    "    # flat pool2 to shape [-1,7*7*64]\n",
    "    flat_layer = tf.reshape(pool2,[-1,7*7*64],name=\"flat_layer\")\n",
    "    \n",
    "    # use two fully connected layers\n",
    "    if use_two_fl:\n",
    "        # fl_1 (fully connected layer 1) ,shape: [-1,7*7*64,1024]\n",
    "        fl_1 = fl_fun(\"fl_1\",flat_layer,7*7*64,1024)\n",
    "        # fl_2, shape [-1,10], as logits\n",
    "        fl_2 = fl_fun(\"fl_2\",fl_1,1024,10)\n",
    "    # only use one fl\n",
    "    else:\n",
    "        # fl_2, shape [-1,10], as logits\n",
    "        fl_2 = fl_fun(\"fl_2\",flat_layer,7*7*64,10)\n",
    "        \n",
    "        \n",
    "    # predictive y class\n",
    "    y_pred_cls = tf.arg_max(fl_2,1)\n",
    "\n",
    "    \n",
    "    y_true = tf.placeholder(tf.float32,[None,10],name=\"y_true\")\n",
    "    y_true_cls = tf.arg_max(y_true,1,name=\"y_true_cls\")\n",
    "\n",
    "    # cost \n",
    "    with tf.name_scope(\"cost\"):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=fl_2,name=\"cross_entropy\")\n",
    "        cost = tf.reduce_mean(cross_entropy)\n",
    "        # summary cost \n",
    "        tf.summary.scalar(\"cost\",cost)\n",
    "    # use  AdamOptimizer to train the model    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "    # accuracy    \n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        equals = tf.equal(y_pred_cls,y_true_cls)\n",
    "        accuracy = tf.reduce_mean(tf.cast(equals,dtype=tf.float32))\n",
    "        # summary accuracy\n",
    "        tf.summary.scalar(\"accuracy\",accuracy)\n",
    "        \n",
    "    # initial session and variables\n",
    "    session = tf.Session()\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    # merge all summaries\n",
    "    summary_merged = tf.summary.merge_all()\n",
    "    # write graph and summaries to train writer\n",
    "    train_writer = tf.summary.FileWriter('./log/train_'+generate(lr,use_two_conv,use_two_fl)    ,graph=session.graph)\n",
    "    # writw summaries to test writer\n",
    "    test_writer = tf.summary.FileWriter('./log/test_'+generate(lr,use_two_conv,use_two_fl) )\n",
    "    \n",
    "    batch_size = 100;\n",
    "    with tf.name_scope(\"train_iterals\"):\n",
    "        for i in range(6000):\n",
    "            batch = data.train.next_batch(batch_size)\n",
    "            feed_dict_batch = {x:batch[0],y_true:batch[1]}\n",
    "            print i\n",
    "            if i % 5 == 0:\n",
    "                s,acc =  session.run([summary_merged,accuracy],feed_dict=feed_dict_batch)\n",
    "                train_writer.add_summary(s,i)\n",
    "                print 'Train_'+generate(lr,use_two_conv,use_two_fl)+\"acc:{:0.1%}\".format(acc)\n",
    "            if i % 10 == 0:\n",
    "                feed_dict_test = {\n",
    "                    x : data.test.images,\n",
    "                    y_true: data.test.labels\n",
    "                }\n",
    "                s,acc = session.run([summary_merged,accuracy],feed_dict=feed_dict_test)\n",
    "                test_writer.add_summary(s,i)\n",
    "                print 'Test_'+generate(lr,use_two_conv,use_two_fl)+\" acc:{:0.1%}\".format(acc)\n",
    "            \n",
    "            \n",
    "            session.run(optimizer,feed_dict=feed_dict_batch)    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different conditions\n",
    "# learning rate in [0.001,0.0001]\n",
    "for lr in [0.001,0.0001]:\n",
    "    # use one or two conv layers\n",
    "    for use_two_conv in [True,False]:\n",
    "        # use one or two fl\n",
    "        for use_two_fl in [True,False]:\n",
    "            # start model , and evaluate it\n",
    "            minst_model(lr,use_two_conv,use_two_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
